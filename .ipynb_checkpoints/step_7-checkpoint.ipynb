{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c266c3b",
   "metadata": {},
   "source": [
    "# 从图像学习神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822121e0",
   "metadata": {},
   "source": [
    "使用 `CIFAR-10` 模型学习，它由 60000 张微小的图像组成，用一个整数对应 10 个级别中的一个：飞机（0）、汽车（1）、鸟（2）、猫（3）、鹿（4）、狗（5）、青蛙（6）、马（7）、船（8）、卡车（9）。\n",
    "\n",
    "使用 `TorchVision` 模块的 `datasets` 模块下载 `CIFAR-10` 数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb53004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "data_path = \"../data-unversioned/p1ch7/\"\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6e82e",
   "metadata": {},
   "source": [
    "下载完数据后，数据集都作为了 `torch.utils.data.Dataset` 的子类方法返回，可以通过实例中的方法解析顺序看到它的父类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b718430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c8db2",
   "metadata": {},
   "source": [
    "## Dataset 类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82b29f",
   "metadata": {},
   "source": [
    "`Dataset` 是需要实现两个方法的对象： `__len__()` 和 `__getitem__()` ，前者返回数据中的项数，后者返回由样本和与之相对应的标签（整数索引）组成的项。在实践中，当一个 `Python` 对象实现了 `__len__()` 方法时，可以将其作为参数传递给 `Python` 的内置函数 `len()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9996206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cifar10), len(cifar10_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c858da",
   "metadata": {},
   "source": [
    "类似地，由于 `Dataset` 实现了 `__get_item__()` 方法，我们可以使用标准索引对元组或列表进行索引访问单个项。在这个例子中，我们得到一个带有期望输出的 PIL(Python Imaging Library) 图像，输出值为 1 ，对应图像数据集中的 *汽车* ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8313d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = cifar10[99]\n",
    "image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b964d",
   "metadata": {},
   "source": [
    "这个图像可以由 `matplotlib` 画出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af688dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e16704",
   "metadata": {},
   "source": [
    "### Dataset 变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6156e5",
   "metadata": {},
   "source": [
    "我们现在已经获取到了图像数据，但是还需要一种办法来将 `PIL` 图像转换成 `PyTorch` 张量，这样我们才能使用图像来做一些其他的事，因此需要导入 `torchvision.transforms` 模块。这个模块定义了一组可组合的、类似于函数的对象，它可以作为参数传递到 `TorchVision` 模块的数据集，在数据加载之后、 `__getitem__()` 方法返回之前对数据进行变换。我们可以先看看可用对象的列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2c16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0d33f",
   "metadata": {},
   "source": [
    "在这些变化对象中，可以看到 `ToTensor` 对象，它将 `NumPy` 数组和 `PIL` 图像变换成张量。它还将输出张量的尺寸设置为 `C*H*W` ，这正是我们所需要的。现在先来试一试 `ToTensor` 变换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782fb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(image)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bad71f",
   "metadata": {},
   "source": [
    "图像已变换成 3 * 32 * 32 的张量，即一个有 3 个通道 (RGB) 的 32 * 32 的图像，这正是我们期望的，现在我们可以将变换作为参数直接传入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a903a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path,\n",
    "                                  train=True,\n",
    "                                  download=False,\n",
    "                                  transform=transforms.ToTensor())\n",
    "tensor_cifar10_val = datasets.CIFAR10(data_path,\n",
    "                                  train=False,\n",
    "                                  download=False,\n",
    "                                  transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77b628",
   "metadata": {},
   "source": [
    "此时访问元素数据将返回一个张量，而不是 PIL 图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1259dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = tensor_cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f25bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f52b28",
   "metadata": {},
   "source": [
    "可以看到正如预期的那样，形状的第一维是通道，而标量类型是 `float32` 。原始的 PIL 图像中的值为 0～255 （RGB），而 `ToTensor` 变换为每个通道的 32 位浮点数，将其值缩小为 0.0～1.0 ，可以验证一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a313c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74616724",
   "metadata": {},
   "source": [
    "在验证一下得到的图像是否相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb430a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102af76",
   "metadata": {},
   "source": [
    "可以看到得到的数据和之前是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680ecc1",
   "metadata": {},
   "source": [
    "### 数据归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbe632",
   "metadata": {},
   "source": [
    "数据变化非常方便，我们可以通过 `transforms.Compose()` 将它们连接起来，然后在数据加载器中透明的进行数据归一化和数据增强操作。\n",
    "\n",
    "现在开始尝试进行归一化：*每个通道的平均值为 0 ,标准差为 1* 。归一化的的原因主要是：可以通过选择在 0±1（或 2 ） 附近呈线性的激活函数，将数据保持在相同的范围内且更有可能具有非零梯度，在这种情况下可以更快的进行学习；同时，对每个通道进行归一化，使其具有相同的分布，可以在保证相同的学习率下，通过剃度下降实现通道信息的混合和更新。\n",
    "\n",
    "`进行归一化的主要原因是为了让数据保持在相同的范围内并更容易进行学习。通过归一化，数据的分布可以更加均匀，可以避免某些特征对模型的影响过大，提高模型的稳定性和泛化能力。此外，归一化后的数据可以更容易地选择合适的激活函数，并且在训练时更容易收敛。在实际应用中，归一化技术已经被广泛应用于各种深度学习模型中，包括卷积神经网络、循环神经网络等。`\n",
    "\n",
    "为了使每个通道的均值为 0 ，标准差为 1 ，可以应用以下转换来计算数据集中每个通道的平均值和标准差：\n",
    "` v_n[c] = (v[c] - mean[c])/stdev[c] `\n",
    "需要注意的是平均值和标准差都需要离线计算，现在让我们计算 `CIFAR-10` 训练集的平均值和标准差。\n",
    "\n",
    "首先需要返回数据集中所有的数据，并将他们在一个额外的维度上进行堆叠（计算整个数据集上的平均值和标准差）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ac8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "imgs = torch.stack([img_t for img_t,_ in tensor_cifar10], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a40245",
   "metadata": {},
   "source": [
    "现在我们可以很容易的计算出每个信道的平均值和标准差："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9c6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只保留了第一维，即三个通道，并将剩余的维度合并成一个维度\n",
    "mean = imgs.view(3, -1).mean(dim=1)\n",
    "std = imgs.view(3, -1).std(dim=1)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2525e1e",
   "metadata": {},
   "source": [
    "有了这些数据就可以使用 `Normalize` 变换了。\n",
    "接下来将其连接到 `ToTensor` 变换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f067c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(data_path,\n",
    "                 train=True,\n",
    "                 download=False,\n",
    "                 transform=transforms.Compose([\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                          (0.2470, 0.2435, 0.2616))\n",
    "                 ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25780a",
   "metadata": {},
   "source": [
    "注意，此时从数据集绘制的图像不能为我们提供真实的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbe6bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d6beb",
   "metadata": {},
   "source": [
    "上面就是重新归一化后得到的红色汽车的图像，归一化对 RGB 超过 0.0~1.0 的数据进行了转化，并调整了通道大小，但所有数据任然存在，只是将其渲染成了黑色。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bcc2e",
   "metadata": {},
   "source": [
    "## 区分鸟和飞机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75eac0",
   "metadata": {},
   "source": [
    "在接下来的目标中是从 `cifar10` 数据中区分鸟和飞机。首先我们要构建出数据集，数据集从 `cifar10` 数据中进行过滤，重新映射标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b794db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in transformed_cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in tensor_cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f7e60",
   "metadata": {},
   "source": [
    "`cifar2` 对象已满足了 `Dataset` 的条件——实现了 `__len__()` 和 `__getitem__()` 方法。\n",
    "\n",
    "现在我们已经有了一个数据集，下一步我们需要一个模型，并把数据提供给它。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00462c",
   "metadata": {},
   "source": [
    "### 一个全连接模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083a3fd",
   "metadata": {},
   "source": [
    "目前先不考虑图片的空间结构部分，理论上如果把图像象素拉成一个一维向量，就可以把这些数字当成输入特征。在这个例子中，我们每个样本的输入特征都有 `3*32*32` 即 3072 个特征。暂时我们先使用线性模块（nn.Linear），它有 3072 个输入特征和一些隐藏的输出特征，接着是一个激活函数，然后使用另一个线性模块使网络的输出特征逐渐减小到合适的数量（2个）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce09503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, n_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86cf25",
   "metadata": {},
   "source": [
    "目前任意选择了 512 个隐藏特征。需要注意的是神经网络至少需要一个隐藏层，否则它只是一个线性模型。现在我们已经有一个模型了，接下来看看模型输出应该是什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da5c26",
   "metadata": {},
   "source": [
    "### 分类器的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69530d0b",
   "metadata": {},
   "source": [
    "在之前的例子中，网络将预测温度（一个具体有意义的数字）作为输出。我们可以在这里做一些类似的事：使我们的网络输出一个单一的标量值，将标签转换为 float 类型（0.0 代表飞机， 1.0 代表鸟），并将这些作为 `MSELoss()` 的目标。这样做就把这个问题转换成了回归问题。但更仔细的看看，我们现在正在处理一些本质上有点不一样的事情（在“概率”向量上使用距离比在分类数字上使用 `MSELoss()` 好得多）。\n",
    "\n",
    "现在我们需要认识到输出是分类的：它要么是一只鸟要么是一架飞机。当我们必须表示一个分类变量时，我们应该使用该变量的独热编码表示，如对飞机使用 [1,0] 对于鸟使用 [0,1] ，顺序任意。\n",
    "\n",
    "在理想情况下，网络将飞机输出 `troch.tensor([1.0,0.0])` ，为鸟输出 `torch.tensor([0.0,1.0])` 。但实际上，我们的分类器并不是很完美，我们可以期望网络输出介于二者之间的结果。在这种情况下，关键的实现是我们可以将输出解释为概率：第一项是“飞机”的概率，第二项是“鸟“的概率。\n",
    "\n",
    "根据概率来处理问题会对我们的网络输出施加一些额外的约束：\n",
    "* 输入的每个元素都必须在[0.0,1.0]之间\n",
    "* 输出元素的总和必须为 1.0\n",
    "\n",
    "这听起来是很难用可微的方式对数字向量进行限制的问题，但是有一个非常有用的函数可以做到这一点，并且它是可微的： `Softmax`\n",
    "\n",
    "\n",
    "当我们需要将一组数值转换为概率分布时，可以使用softmax函数。它将一组任意实数转换为表示概率的正数，并确保它们总和为1。\n",
    "\n",
    "具体来说，对于给定的向量 $z = [z_1, z_2, ..., z_k]$，softmax函数可以定义为：\n",
    "\n",
    "$$\\text{softmax}(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}$$\n",
    "\n",
    "其中 $i$ 是向量中的任意索引。这将计算每个元素 $z_i$ 的指数，并将它们除以所有指数的总和，从而得到一个表示概率分布的向量。\n",
    "\n",
    "例如，对于向量 $z = [1, 2, 3]$，softmax函数将计算：\n",
    "\n",
    "$$\\text{softmax}(z) = \\left[\\frac{e^1}{e^1 + e^2 + e^3}, \\frac{e^2}{e^1 + e^2 + e^3}, \\frac{e^3}{e^1 + e^2 + e^3}\\right] = [0.09, 0.24, 0.67]$$\n",
    "\n",
    "这个结果告诉我们，第一个元素是 $z$ 中所有元素的概率为 $9\\%$，第二个元素的概率为 $24\\%$，第三个元素的概率为 $67\\%$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef74f08",
   "metadata": {},
   "source": [
    "### 用概率表示输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce3336",
   "metadata": {},
   "source": [
    "`softmax` 函数会获取一个值并生成另一个相同维度的向量，每个位置的就是每个位置的概率。接下来可以定义 `softmax` 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac0698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d372af",
   "metadata": {},
   "source": [
    "现在可以输入一个向量测量它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272d464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0,2.0,3.0])\n",
    "softmax(x),softmax(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de94a73",
   "metadata": {},
   "source": [
    "`torch.nn` 模块中也存在 `Softmax` 函数，不过该函数被作为一个模块，它需要我们指定用来编码概率的维度，因为在通常情况下，输入张量可能有额外的第 0 维，或者有一个沿其编码概率的维度和其他维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9f04701",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a1ce2",
   "metadata": {},
   "source": [
    "现在我们可以在模型的末尾添加一个 `nn.Softmax()` ，这样我们的网络就可以产生概率了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4570890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2),\n",
    "                      nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ceb03",
   "metadata": {},
   "source": [
    "现在我们可以尝试运行它，不过首先我们需要构建一个图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fda9546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d9181",
   "metadata": {},
   "source": [
    "现在，我们有一个鸟的图像，但是在把图像传给模型之前我们需要做一些额外的事：使输入具有正确的维度。在这个例子中，我们的模型在输入中期望有 3072 个特征，而 `nn` 模块处理的是沿着第 0 维成批组织的数据，所以我们需要把 `3*32*32` 的图像变成一个一维数组，然后增加一个第 0 维的维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c46f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d1a43",
   "metadata": {},
   "source": [
    "接下来就可以调用模型了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1a85760",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f8117",
   "metadata": {},
   "source": [
    "现在，我们得到了两种分类的概率，但是需要注意的是线性层的权重和偏置还没训练过，现在它们的值还都是 `PyTorch` 随即生成的 -1.0~1.0 的数据。不过我们现在能看到 `grad_fn` 属性，它位于后向计算图的顶端。\n",
    "\n",
    "此外，虽然我们知道输出概率应该是多少（class_name），但现在的网络还没有这样的指示。第一项是“飞机”，第二项是“鸟”，还是相反？此时的网络还无法分辨。反向传播过后，损失函数将标签和这两个数字联系起来。如果所提供的标签将“飞机”的索引设置为 0 ，“鸟” 设置为 1,那么这就是导出的输出顺序。在训练后我们能通过计算输出概率的 `argmax` 计算作为索引的标签，即获得最大概率的索引。方便的是，可以通过 `torch.max()` 方法和维度，计算出该维度上最大元素以及该值出现的索引。在这个例子中，我们需要沿着概率方向取最大值，因此维度为 1 （输出存在一个默认的第 0 维——批次）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05ff7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0d77f",
   "metadata": {},
   "source": [
    "### 分类的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad03f28",
   "metadata": {},
   "source": [
    "在上面的内容中提到了损失是赋予两个标签概率意义的东西，在之前的线性模型的例子中我们使用了 `MSE` 作为损失函数，现在我们依旧能使用 `MSE` ，使输出收敛到[0.0,1.0]和[1.0,0.0]。但是在这个例子中我们并不是真的对精确地再现这些值感兴趣，我们真的感兴趣的是：对于飞机来说，第一个概率高于第二个，对于鸟来说，第二个概率高于第一个。换句话说，我们希望惩罚错误分类，而不是煞费苦心地惩罚那些完全不像 0.0 或 1.0 的东西。\n",
    "\n",
    "在这种情况下，我们需要最大化的是与正确的类相关的概率。正确的类别相关的概率，被称为我们的模型给定参数的似然。换句话说，我们想要一个损失函数，当概率很低的时候，损失非常高（低到其他选择都有比它更高的概率），相反，当概率很低的时候，损失应该很低，而且我们并不是真的专注于将概率提高到 1 。\n",
    "\n",
    "有一个损失函数就是这样的，它被称为负对数似然（NLL）。他的表达式为：\n",
    "$$NLL = -sum(log(out_i[c_i]))$$\n",
    "其中 `sum()` 对于 N 个样本求和，而 `c_i` 是样本 i 的目标类别，下图就是该函数的函数图：\n",
    "\n",
    "![](./data/images/NLL.png)\n",
    "\n",
    "据上图可以看出当预测目标类别概率较低时， `NLL` 会增长到无穷大，而当预测目标类别概率大于 0.5 时， `NLL` 的下降速度非常慢。\n",
    "\n",
    "`“负对数似然”是一个在统计学和机器学习中常用的术语。它是指将似然函数取负数后再取对数得到的值，通常用于最小化损失函数。在实际应用中，负对数似然经常用于分类问题中的逻辑回归模型，其中目标是最大化似然函数，即最大化正确分类的概率。通过将似然函数取负数并取对数，可以将最大化问题转化为最小化问题，从而更容易优化。`\n",
    "\n",
    "`似然函数可以理解为一个数学公式，它描述了我们观察到的数据和模型参数之间的关系，并且可以用来衡量模型对数据的拟合程度。举个例子，假设我们有一组数据，想要用一个模型来预测这些数据。我们可以根据这组数据来计算一个似然函数，这个函数会告诉我们在给定模型参数的情况下，观察到这组数据的概率大小。如果我们希望找到最优的模型参数，就需要最大化这个似然函数，从而使得模型对数据的拟合程度最好。`\n",
    "\n",
    "综上所述，对于批次中的每个样本，分类损失可以按以下步骤计算：\n",
    "\n",
    "1. 运行正向传播，并从最后的线性层获取输出值。\n",
    "2. 计算它们的 `Softmax` ，获取概率。\n",
    "3. 取与目标类别对应的预测概率。\n",
    "4. 计算它的对数，在他前面加上一个负号，在添加到损失中\n",
    "\n",
    "那么在 `PyTorch` 中应该怎么做呢？ `PyTorch` 有一个 `nn.NLLLoss` 类，但是与现在期望的有些不同：它没有取概率张量而是取对数概率张量作为输入，这样做的原因是当概率接近于 0 时，去概率的对数是很棘手的事。解决办法就是使用 `nn.LogSoftmax()` 而不是使用 `nn.Softmax()`，确保计算在数值上的稳定。\n",
    "\n",
    "下面是我们的新的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ade5ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6e87c",
   "metadata": {},
   "source": [
    "然后实例化 NLL 损失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3461edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9819cc",
   "metadata": {},
   "source": [
    "损失将批次的 `nn.LogSoftmax()` 的输出作为第一个参数，将类别索引的张量作为第二个参数，现在我们可以用鸟来测试它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "549b84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar2[0]\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54eb93e",
   "metadata": {},
   "source": [
    "### 训练分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c8170",
   "metadata": {},
   "source": [
    "回想之前的例子中，训练只有一个循环，它会在一个训练循环中一次性对所有的样本数据进行评估。但在现在这个例子中，一个批处理中处理上万张图像太多了，所以需要在循环内部再进行一次循环，每次只评估小批量的数据，并在小批量的数据上进行反向传播。并且在实践中，小批量上的估计梯度有助于收敛，并防止训练过程中陷入局部最小值。\n",
    "\n",
    "在 `torch.utils.data` 模块有一个 `DataLoader` 类，该类有助于打乱数据和组织数据，并且他还支持多种策略，最常见的就是在每个迭代周期洗牌后进行均匀采样，现在看一下使用的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d880d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e2e46",
   "metadata": {},
   "source": [
    "`DataLoader` 构造函数至少接收一个数据集对象作为输入， `batch_size` 指定每批次采样的数据量， `shuffle` 指示数据是否要需要在周期开始时被重新打乱。现在可以在迭代循环中使用它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dce5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(),\n",
    ")\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "def train(n_epochs,data_loader,loss_fn,optimizer,model):\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in data_loader:\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.view(batch_size, -1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "\n",
    "train(n_epochs=n_epochs,data_loader=train_loader,loss_fn=loss_fn,optimizer=optimizer,model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b09fda",
   "metadata": {},
   "source": [
    "可以看到损失以某种方式减少了，但是还不知道降低的是否足够低。现在可以在验证集上进行验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(cifar2_val,batch_size=64,shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size,-1))\n",
    "        _,predicted = torch.max(outputs,dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy:\",correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcdb8d9",
   "metadata": {},
   "source": [
    "可以看到虽然性能不是很好，但比随机要好得多。性能不好的原因是现在我们的模型只是一个非常浅的模型，它起作用的原因可能是因为数据集非常简单，这两个类中的很多样本可能存在系统性差异，如背景颜色，这有助于模型根据几个像素区分鸟和飞机。\n",
    "\n",
    "当然，我们也可以通过添加更多的图层来增加模型的深度和容量，一种比较随意的做法是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fa343",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = nn.Sequential(nn.Linear(3072, 1024), nn.Tanh(),\n",
    "                          nn.Linear(1024, 512), nn.Tanh(), nn.Linear(512, 128),\n",
    "                          nn.Tanh(), nn.Linear(128, 2), nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448e2c6",
   "metadata": {},
   "source": [
    "在新的模型里面，我们试图减少输出端的特征数量，希望中间层能更好的压缩信息。可以尝试运行新的模型测试：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(n_epochs=n_epochs,data_loader=train_loader,loss_fn=loss_fn,optimizer=optimizer,model=new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a83be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
